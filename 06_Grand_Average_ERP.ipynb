{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd0e8a0",
   "metadata": {},
   "source": [
    "# 06 Grand Average ERP Analysis\n",
    "\n",
    "## Overview\n",
    "This notebook combines all participants (Sessions 0, 1, 4) into a **grand average** for publication-quality ERP analysis.\n",
    "\n",
    "**Purpose:**\n",
    "- Pool EEG data across all 3 participants for increased statistical power\n",
    "- Generate grand average ERPs showing condition effects (high/medium/low alignment)\n",
    "- Create publication-ready figures and summary statistics\n",
    "- Export results for manuscript tables\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run Notebook 05 (ERP Analysis) for each session first to generate epoch files\n",
    "- Requires: `session_XX-epochs-epo.fif` files in `./preprocessed/`\n",
    "\n",
    "**What it does:**\n",
    "1. Loads preprocessed epochs from all 3 sessions\n",
    "2. Combines epochs across participants\n",
    "3. Computes grand average for each condition\n",
    "4. Identifies ERP components (N1, P2, P300, N400, LPP)\n",
    "5. Generates comprehensive visualizations\n",
    "6. Exports summary statistics for manuscript\n",
    "\n",
    "**Output:**\n",
    "- Grand average ERP waveforms (Cz, Pz electrodes)\n",
    "- Topographic maps at key latencies\n",
    "- Condition comparison plots\n",
    "- Summary tables (CSV) for manuscript\n",
    "\n",
    "**Code Attribution:**\n",
    "- Analysis workflow adapted from: Chiossi, F., Mayer, S., & Ou, C. (2024). MobileHCI 2024 Papers.\n",
    "- OSF Repository: https://osf.io/fncj4/overview\n",
    "- License: GNU General Public License (GPL) 3.0\n",
    "- Code has been modified for multi-participant grand average analysis.\n",
    "\n",
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1c551c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported\n",
      "MNE version: 1.11.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "print(\"âœ“ Libraries imported\")\n",
    "print(f\"MNE version: {mne.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef20684b",
   "metadata": {},
   "source": [
    "## 2. Load All Sessions and Combine Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a6fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LOADING ALL SESSIONS FOR GRAND AVERAGE\n",
      "================================================================================\n",
      "\n",
      "Loading Session 0...\n",
      "  âœ“ Loaded 1 epochs\n",
      "  Conditions: ['high', 'low']\n",
      "\n",
      "Loading Session 1...\n",
      "  âœ“ Loaded 5 epochs\n",
      "  Conditions: ['high', 'medium', 'low']\n",
      "  âš  File not found: ./preprocessed/session_04-epochs-epo.fif\n",
      "  â†’ Run Notebook 05 for Session 4 first to generate epoch files\n",
      "\n",
      "================================================================================\n",
      "COMBINING 2 SESSIONS\n",
      "================================================================================\n",
      "\n",
      "Combined epochs:\n",
      "  Total epochs: 6\n",
      "  Conditions: ['high', 'low', 'medium']\n",
      "  Participants: [np.int64(0), np.int64(1)]\n",
      "  Channels: 64\n",
      "  Sampling rate: 500.0 Hz\n",
      "  Time range: -0.5 to 0.8 s\n",
      "\n",
      "âœ“ Data loading complete\n",
      "  âœ“ Loaded 1 epochs\n",
      "  Conditions: ['high', 'low']\n",
      "\n",
      "Loading Session 1...\n",
      "  âœ“ Loaded 5 epochs\n",
      "  Conditions: ['high', 'medium', 'low']\n",
      "  âš  File not found: ./preprocessed/session_04-epochs-epo.fif\n",
      "  â†’ Run Notebook 05 for Session 4 first to generate epoch files\n",
      "\n",
      "================================================================================\n",
      "COMBINING 2 SESSIONS\n",
      "================================================================================\n",
      "\n",
      "Combined epochs:\n",
      "  Total epochs: 6\n",
      "  Conditions: ['high', 'low', 'medium']\n",
      "  Participants: [np.int64(0), np.int64(1)]\n",
      "  Channels: 64\n",
      "  Sampling rate: 500.0 Hz\n",
      "  Time range: -0.5 to 0.8 s\n",
      "\n",
      "âœ“ Data loading complete\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING ALL SESSIONS FOR GRAND AVERAGE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sessions to include (N=3 participants)\n",
    "sessions_to_load = [0, 1, 4]\n",
    "all_epochs = []\n",
    "\n",
    "for sess_id in sessions_to_load:\n",
    "    epochs_file = f'./preprocessed/session_{sess_id:02d}-epochs-epo.fif'\n",
    "    \n",
    "    if Path(epochs_file).exists():\n",
    "        print(f\"\\nLoading Session {sess_id}...\")\n",
    "        epochs = mne.read_epochs(epochs_file, preload=True, verbose=False)\n",
    "        \n",
    "        # Add session info to metadata\n",
    "        if epochs.metadata is None:\n",
    "            epochs.metadata = pd.DataFrame({'session_id': [sess_id] * len(epochs)})\n",
    "        else:\n",
    "            epochs.metadata['session_id'] = sess_id\n",
    "        \n",
    "        all_epochs.append(epochs)\n",
    "        print(f\"  âœ“ Loaded {len(epochs)} epochs\")\n",
    "        print(f\"  Conditions: {list(epochs.event_id.keys())}\")\n",
    "    else:\n",
    "        print(f\"  âš  File not found: {epochs_file}\")\n",
    "        print(f\"  â†’ Run Notebook 05 for Session {sess_id} first to generate epoch files\")\n",
    "\n",
    "if not all_epochs:\n",
    "    raise FileNotFoundError(\"No epoch files found! Run Notebook 05 for each session first.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"COMBINING {len(all_epochs)} SESSIONS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Combine all epochs\n",
    "combined_epochs = mne.concatenate_epochs(all_epochs)\n",
    "\n",
    "print(f\"\\nCombined epochs:\")\n",
    "print(f\"  Total epochs: {len(combined_epochs)}\")\n",
    "print(f\"  Conditions: {list(combined_epochs.event_id.keys())}\")\n",
    "print(f\"  Participants: {sorted(combined_epochs.metadata['session_id'].unique())}\")\n",
    "print(f\"  Channels: {len(combined_epochs.ch_names)}\")\n",
    "print(f\"  Sampling rate: {combined_epochs.info['sfreq']} Hz\")\n",
    "print(f\"  Time range: {combined_epochs.tmin} to {combined_epochs.tmax} s\")\n",
    "print(f\"\\nâœ“ Data loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ffab8",
   "metadata": {},
   "source": [
    "## 3. Compute Grand Average ERPs by Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257795c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPUTING GRAND AVERAGE ERPs\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "epochs.average() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m combined_epochs.event_id.keys():\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m         evoked = \u001b[43mcombined_epochs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m         grand_avg_evoked[condition] = evoked\n\u001b[32m     12\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcondition.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimbe\\iCloudDrive\\Master\\Masterarbeit\\Analyse\\.venv\\Lib\\site-packages\\mne\\epochs.py:1108\u001b[39m, in \u001b[36mBaseEpochs.average\u001b[39m\u001b[34m(self, picks, method, by_event_type)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;129m@fill_doc\u001b[39m\n\u001b[32m   1068\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maverage\u001b[39m(\u001b[38;5;28mself\u001b[39m, picks=\u001b[38;5;28;01mNone\u001b[39;00m, method=\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m, by_event_type=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1069\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute an average over epochs.\u001b[39;00m\n\u001b[32m   1070\u001b[39m \n\u001b[32m   1071\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1106\u001b[39m \u001b[33;03m    This would compute the trimmed mean.\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraise\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maverage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1109\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m by_event_type:\n\u001b[32m   1110\u001b[39m         evokeds = \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimbe\\iCloudDrive\\Master\\Masterarbeit\\Analyse\\.venv\\Lib\\site-packages\\mne\\epochs.py:1596\u001b[39m, in \u001b[36mBaseEpochs._handle_empty\u001b[39m\u001b[34m(self, on_empty, meth)\u001b[39m\n\u001b[32m   1590\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.events) == \u001b[32m0\u001b[39m:\n\u001b[32m   1591\u001b[39m     msg = (\n\u001b[32m   1592\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepochs.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeth\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt run because this Epochs-object is empty. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1593\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou might want to check Epochs.drop_log or Epochs.plot_drop_log()\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1594\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m to see why epochs were dropped.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1595\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m     \u001b[43m_on_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_empty\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_klass\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kimbe\\iCloudDrive\\Master\\Masterarbeit\\Analyse\\.venv\\Lib\\site-packages\\mne\\utils\\check.py:1221\u001b[39m, in \u001b[36m_on_missing\u001b[39m\u001b[34m(on_missing, msg, name, error_klass)\u001b[39m\n\u001b[32m   1219\u001b[39m on_missing = \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mwarning\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[32m   1220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[32m   1222\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m on_missing == \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1223\u001b[39m     warn(msg)\n",
      "\u001b[31mRuntimeError\u001b[39m: epochs.average() can't run because this Epochs-object is empty. You might want to check Epochs.drop_log or Epochs.plot_drop_log() to see why epochs were dropped."
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMPUTING GRAND AVERAGE ERPs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# First, check what conditions we have and their epoch counts\n",
    "print(\"\\nChecking epoch counts per condition:\")\n",
    "for condition in combined_epochs.event_id.keys():\n",
    "    n_epochs = len(combined_epochs[condition])\n",
    "    print(f\"  {condition}: {n_epochs} epochs\")\n",
    "\n",
    "# Compute grand averages for each condition\n",
    "grand_avg_evoked = {}\n",
    "\n",
    "for condition in combined_epochs.event_id.keys():\n",
    "    try:\n",
    "        # Check if condition has any epochs\n",
    "        condition_epochs = combined_epochs[condition]\n",
    "        n_epochs = len(condition_epochs)\n",
    "        \n",
    "        if n_epochs == 0:\n",
    "            print(f\"\\nâš  WARNING: '{condition}' has 0 epochs - skipping\")\n",
    "            print(f\"  Check drop_log for why epochs were dropped\")\n",
    "            continue\n",
    "        \n",
    "        # Compute average\n",
    "        evoked = condition_epochs.average()\n",
    "        grand_avg_evoked[condition] = evoked\n",
    "        \n",
    "        print(f\"\\n{condition.upper()}:\")\n",
    "        print(f\"  N epochs: {evoked.nave}\")\n",
    "        print(f\"  Time range: {evoked.times[0]:.3f} to {evoked.times[-1]:.3f} s\")\n",
    "        print(f\"  Channels: {len(evoked.ch_names)}\")\n",
    "        data_uv = evoked.data * 1e6\n",
    "        print(f\"  Amplitude range: {np.min(data_uv):.2f} to {np.max(data_uv):.2f} ÂµV\")\n",
    "        \n",
    "    except KeyError:\n",
    "        print(f\"\\nâš  Condition '{condition}' not found in epochs\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"\\nâš  Error processing '{condition}': {e}\")\n",
    "\n",
    "if not grand_avg_evoked:\n",
    "    raise ValueError(\"No conditions could be averaged! Check your epoch files and condition labels.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"GRAND AVERAGE SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total participants: N = {len(sessions_to_load)}\")\n",
    "print(f\"Total epochs combined: {len(combined_epochs)}\")\n",
    "print(f\"Conditions successfully averaged: {list(grand_avg_evoked.keys())}\")\n",
    "print(f\"\\nâœ“ Grand average computation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280fdaee",
   "metadata": {},
   "source": [
    "## 4. Grand Average Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cdb792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot grand average ERPs for key electrodes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Define key electrodes and condition colors\n",
    "key_electrodes = ['Cz', 'Pz']\n",
    "colors = {'high': 'green', 'medium': 'orange', 'low': 'red'}\n",
    "\n",
    "# Top row: Cz and Pz waveforms\n",
    "for idx, electrode in enumerate(key_electrodes):\n",
    "    ax = axes[0, idx]\n",
    "    \n",
    "    for condition, evoked in grand_avg_evoked.items():\n",
    "        if electrode in evoked.ch_names:\n",
    "            ch_idx = evoked.ch_names.index(electrode)\n",
    "            data_uv = evoked.data[ch_idx, :] * 1e6\n",
    "            times_ms = evoked.times * 1000\n",
    "            \n",
    "            color = colors.get(condition, 'gray')\n",
    "            ax.plot(times_ms, data_uv, label=f'{condition} (N={evoked.nave})', \n",
    "                   color=color, linewidth=2)\n",
    "    \n",
    "    ax.axhline(0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "    ax.axvline(0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "    ax.set_xlabel('Time (ms)', fontsize=12)\n",
    "    ax.set_ylabel('Amplitude (ÂµV)', fontsize=12)\n",
    "    ax.set_title(f'Grand Average ERP - {electrode}', fontsize=14, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Shade typical component windows\n",
    "    ax.axvspan(80, 150, alpha=0.1, color='blue', label='N1')\n",
    "    ax.axvspan(150, 250, alpha=0.1, color='cyan', label='P2')\n",
    "    ax.axvspan(300, 500, alpha=0.1, color='purple', label='P3/N400')\n",
    "    ax.axvspan(400, 800, alpha=0.1, color='pink', label='LPP')\n",
    "\n",
    "# Bottom left: Butterfly plot - all channels\n",
    "ax_butterfly = axes[1, 0]\n",
    "for condition, evoked in grand_avg_evoked.items():\n",
    "    color = colors.get(condition, 'gray')\n",
    "    for ch_idx in range(len(evoked.ch_names)):\n",
    "        data_uv = evoked.data[ch_idx, :] * 1e6\n",
    "        times_ms = evoked.times * 1000\n",
    "        ax_butterfly.plot(times_ms, data_uv, color=color, alpha=0.1, linewidth=0.5)\n",
    "\n",
    "ax_butterfly.axhline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "ax_butterfly.axvline(0, color='black', linestyle='--', linewidth=0.8)\n",
    "ax_butterfly.set_xlabel('Time (ms)', fontsize=12)\n",
    "ax_butterfly.set_ylabel('Amplitude (ÂµV)', fontsize=12)\n",
    "ax_butterfly.set_title('Butterfly Plot - All Channels', fontsize=14, fontweight='bold')\n",
    "ax_butterfly.grid(True, alpha=0.3)\n",
    "\n",
    "# Bottom right: Topographic map at P300 peak (~400ms)\n",
    "ax_topo = axes[1, 1]\n",
    "if 'high' in grand_avg_evoked:\n",
    "    evoked_plot = grand_avg_evoked['high']\n",
    "    peak_time = 0.400  # 400ms\n",
    "    \n",
    "    # Find closest time point\n",
    "    time_idx = np.argmin(np.abs(evoked_plot.times - peak_time))\n",
    "    \n",
    "    mne.viz.plot_topomap(evoked_plot.data[:, time_idx], evoked_plot.info, \n",
    "                         axes=ax_topo, show=False, \n",
    "                         cmap='RdBu_r', vlim=(-5, 5))\n",
    "    ax_topo.set_title(f'Topography at {peak_time*1000:.0f} ms (High Alignment)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "\n",
    "fig.suptitle('Grand Average ERPs (N=3 Participants)', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = './figures/grand_average_erp_all_conditions.png'\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved grand average figure to: {fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fee88",
   "metadata": {},
   "source": [
    "## 5. Extract Mean Amplitudes by Component and Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d575f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXTRACTING MEAN AMPLITUDES FOR ERP COMPONENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define time windows for key components\n",
    "time_windows = {\n",
    "    'N1': (0.080, 0.150),\n",
    "    'P2': (0.150, 0.250),\n",
    "    'N2': (0.200, 0.350),\n",
    "    'P300': (0.300, 0.500),\n",
    "    'N400': (0.300, 0.500),\n",
    "    'LPP': (0.400, 0.800),\n",
    "    'Late_Negativity': (0.500, 0.700)\n",
    "}\n",
    "\n",
    "# Define electrodes for each component\n",
    "component_electrodes = {\n",
    "    'N1': ['Oz', 'O1', 'O2'],\n",
    "    'P2': ['Cz', 'Fz'],\n",
    "    'N2': ['Fz', 'FCz'],\n",
    "    'P300': ['Pz', 'Cz', 'CPz'],\n",
    "    'N400': ['Cz', 'Pz'],\n",
    "    'LPP': ['Pz', 'Cz', 'CPz'],\n",
    "    'Late_Negativity': ['Cz', 'Fz']\n",
    "}\n",
    "\n",
    "# Extract mean amplitudes\n",
    "results = []\n",
    "\n",
    "for condition, evoked in grand_avg_evoked.items():\n",
    "    print(f\"\\n{condition.upper()} (N={evoked.nave} epochs):\")\n",
    "    \n",
    "    for component, (tmin, tmax) in time_windows.items():\n",
    "        electrodes = component_electrodes.get(component, ['Cz'])\n",
    "        \n",
    "        # Get available electrodes\n",
    "        available_electrodes = [ch for ch in electrodes if ch in evoked.ch_names]\n",
    "        \n",
    "        if available_electrodes:\n",
    "            # Extract data for time window and electrodes\n",
    "            time_mask = (evoked.times >= tmin) & (evoked.times <= tmax)\n",
    "            \n",
    "            for electrode in available_electrodes:\n",
    "                ch_idx = evoked.ch_names.index(electrode)\n",
    "                data = evoked.data[ch_idx, time_mask] * 1e6  # Convert to ÂµV\n",
    "                \n",
    "                mean_amp = np.mean(data)\n",
    "                peak_amp = data[np.argmax(np.abs(data))]\n",
    "                peak_lat = evoked.times[time_mask][np.argmax(np.abs(data))] * 1000  # ms\n",
    "                \n",
    "                results.append({\n",
    "                    'Condition': condition,\n",
    "                    'Component': component,\n",
    "                    'Electrode': electrode,\n",
    "                    'Time_Window_ms': f\"{tmin*1000:.0f}-{tmax*1000:.0f}\",\n",
    "                    'Mean_Amplitude_ÂµV': mean_amp,\n",
    "                    'Peak_Amplitude_ÂµV': peak_amp,\n",
    "                    'Peak_Latency_ms': peak_lat,\n",
    "                    'N_Epochs': evoked.nave\n",
    "                })\n",
    "                \n",
    "                print(f\"  {component} @ {electrode}: {mean_amp:+.2f} ÂµV (peak: {peak_amp:+.2f} ÂµV @ {peak_lat:.0f} ms)\")\n",
    "\n",
    "# Create DataFrame\n",
    "df_amplitudes = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"AMPLITUDE EXTRACTION COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total measurements: {len(df_amplitudes)}\")\n",
    "print(f\"Components analyzed: {df_amplitudes['Component'].nunique()}\")\n",
    "print(f\"Electrodes used: {df_amplitudes['Electrode'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c27c47",
   "metadata": {},
   "source": [
    "## 6. Condition Comparison and Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b851712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison plots for key components\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "key_components = ['N1', 'P2', 'P300', 'N400', 'LPP', 'Late_Negativity']\n",
    "\n",
    "for idx, component in enumerate(key_components):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    # Filter data for this component\n",
    "    comp_data = df_amplitudes[df_amplitudes['Component'] == component]\n",
    "    \n",
    "    if not comp_data.empty:\n",
    "        # Get primary electrode (first in list)\n",
    "        primary_electrode = comp_data.iloc[0]['Electrode']\n",
    "        electrode_data = comp_data[comp_data['Electrode'] == primary_electrode]\n",
    "        \n",
    "        # Bar plot\n",
    "        conditions = electrode_data['Condition'].values\n",
    "        amplitudes = electrode_data['Mean_Amplitude_ÂµV'].values\n",
    "        colors_list = [colors.get(c, 'gray') for c in conditions]\n",
    "        \n",
    "        bars = ax.bar(conditions, amplitudes, color=colors_list, alpha=0.7, edgecolor='black')\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, amp in zip(bars, amplitudes):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{amp:.2f}', ha='center', va='bottom' if amp > 0 else 'top', fontsize=9)\n",
    "        \n",
    "        ax.axhline(0, color='black', linestyle='-', linewidth=0.8)\n",
    "        ax.set_ylabel('Mean Amplitude (ÂµV)', fontsize=10)\n",
    "        ax.set_title(f'{component} @ {primary_electrode}', fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Add time window info\n",
    "        time_window = electrode_data.iloc[0]['Time_Window_ms']\n",
    "        ax.text(0.5, 0.95, f'[{time_window} ms]', \n",
    "               transform=ax.transAxes, ha='center', va='top', fontsize=8, style='italic')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f'No data for {component}', \n",
    "               transform=ax.transAxes, ha='center', va='center')\n",
    "        ax.set_title(component, fontsize=12, fontweight='bold')\n",
    "\n",
    "fig.suptitle('ERP Component Amplitudes by Condition (Grand Average, N=3)', \n",
    "            fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "fig_path = './figures/grand_average_component_comparison.png'\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved component comparison to: {fig_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Export results to CSV\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXPORTING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save full amplitude table\n",
    "csv_path = './results/grand_average_amplitudes.csv'\n",
    "df_amplitudes.to_csv(csv_path, index=False)\n",
    "print(f\"âœ“ Full amplitude data saved to: {csv_path}\")\n",
    "\n",
    "# Create summary table (pivot by condition and component at primary electrode)\n",
    "summary_data = []\n",
    "for component in key_components:\n",
    "    comp_data = df_amplitudes[df_amplitudes['Component'] == component]\n",
    "    if not comp_data.empty:\n",
    "        primary_electrode = comp_data.iloc[0]['Electrode']\n",
    "        electrode_data = comp_data[comp_data['Electrode'] == primary_electrode]\n",
    "        \n",
    "        for _, row in electrode_data.iterrows():\n",
    "            summary_data.append({\n",
    "                'Component': component,\n",
    "                'Electrode': primary_electrode,\n",
    "                'Time_Window': row['Time_Window_ms'],\n",
    "                'Condition': row['Condition'],\n",
    "                'Mean_Amplitude_ÂµV': f\"{row['Mean_Amplitude_ÂµV']:.2f}\",\n",
    "                'Peak_Amplitude_ÂµV': f\"{row['Peak_Amplitude_ÂµV']:.2f}\",\n",
    "                'Peak_Latency_ms': f\"{row['Peak_Latency_ms']:.0f}\",\n",
    "                'N_Epochs': row['N_Epochs']\n",
    "            })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "summary_path = './results/grand_average_summary.csv'\n",
    "df_summary.to_csv(summary_path, index=False)\n",
    "print(f\"âœ“ Summary table saved to: {summary_path}\")\n",
    "\n",
    "print(\"\\nðŸ“Š GRAND AVERAGE SUMMARY TABLE (for manuscript):\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"âœ… GRAND AVERAGE ANALYSIS COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nResults saved to:\")\n",
    "print(f\"  â€¢ Figures: ./figures/grand_average_*.png\")\n",
    "print(f\"  â€¢ Data: ./results/grand_average_*.csv\")\n",
    "print(f\"\\nTotal participants: N = {len(sessions_to_load)}\")\n",
    "print(f\"Total epochs analyzed: {len(combined_epochs)}\")\n",
    "print(f\"Conditions: {list(grand_avg_evoked.keys())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
